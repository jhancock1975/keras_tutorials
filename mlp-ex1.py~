import keras
from keras.models import Sequential
from keras.layers import Dense, Dropout, Activation
from keras.optimizers import SGD
import numpy as np
import jh_util as jh
import logging

logging.basicConfig(format='%(asctime)s %(message)s', level=logging.DEBUG)
logging.info('starting up')

# Generate dummy data

x_train = np.random.random((1000, 20))
logging.debug('x_train {x}'.format(x = jh.arr_stats(x_train)))


y_train = keras.utils.to_categorical(np.random.randint(10, size=(1000, 1)), num_classes=10)
logging.debug('y_train {y}'.format(y = jh.arr_stats(y_train)))

x_test = np.random.random((100, 20))
logging.debug('x_test {x}'.format(x = jh.arr_stats(x_test)))

y_test = keras.utils.to_categorical(np.random.randint(10, size=(100, 1)), num_classes=10)
logging.debug('y_test {}'.format(jh.arr_stats(y_test)))

model = Sequential()
# Dense(64) is a fully-connected layer with 64 hidden units.
# in the first layer, you must specify the expected input data shape:
# here, 20-dimensional vectors.
model.add(Dense(64, activation='relu', input_dim=20))
model.add(Dropout(0.5))
model.add(Dense(64, activation='relu'))
model.add(Dropout(0.5))
model.add(Dense(10, activation='softmax'))

logging.debug(model.summary())


sgd = SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)
model.compile(loss='categorical_crossentropy',
              optimizer=sgd,
              metrics=['accuracy'])

model.fit(x_train, y_train,
          epochs=20,
          batch_size=128)
score = model.evaluate(x_test, y_test, batch_size=128)
